{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscikit-learn基本功能：分类，回归， 聚类，数据降维， 数据预处理\\n\\n- 获取数据集的方式：\\n1.sklearn.datasets.load_*() 获取小规模数据集，数据集已经随scikit-learn安装而下载了\\n2.sklearn.datasets.fetch_*(data_home = None) 用于从远程获得大规模数据集， 函数第一个参数data_home表示数据集下载的目录\\n\\n- 数据集的方法和属性：\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scikit-learn基本功能：分类，回归， 聚类，数据降维， 数据预处理\n",
    "\n",
    "-- 获取数据集的方式：\n",
    "1. sklearn.datasets.load_*() 获取小规模数据集，数据集已经随scikit-learn安装而下载了\n",
    "2. sklearn.datasets.fetch_*(data_home = None) 用于从远程获得大规模数据集， 函数第一个参数data_home表示数据集下载的目录\n",
    "\n",
    "-- 数据集的方法和属性：\n",
    "1. data：特征数据集(二维的numpy.ndarray数组)\n",
    "2. target: 标签数组(一维的numpy.ndarray数组)\n",
    "3. DESCR: 数据描述\n",
    "4. feature_names: 特征名(新闻数据，手写数字，回归数据没有)\n",
    "5. target_name: 标签名(回归数据没有)\n",
    "\n",
    "-- 数据集划分：(可以使用sklearn.model_selection.train_test_split进行分割)\n",
    "1. x: 数据集的特征值\n",
    "2. y: 数据集的目标值\n",
    "3. test_size: 测试数据的占比，用小数表示\n",
    "返回值如下：\n",
    "1. x_train: 训练部分的特征值\n",
    "2. x_test: 测试部分的特征值\n",
    "3. y_train: 训练部分的目标值\n",
    "4. y_test: 测试部分的目标值\n",
    "\n",
    "-- 本地数据集：\n",
    "---- 分类数据集：\n",
    "1. load_iris: 鸢尾花花瓣数据集\n",
    "2. load_digits: 手写数字数据集\n",
    "3. load_wine: 红酒数据集\n",
    "4. load_breast_cancer: 乳腺癌数据集\n",
    "---- 回归类数据集：\n",
    "1. load_boston: 波士顿房价数据集\n",
    "2. load_diabetes: 糖尿病数据集\n",
    "3. load_linnerud: 体能训练数据集\n",
    "-- 远程数据集：\n",
    "---- 分类数据集：\n",
    "1. fetch_olivetti_faces: 面孔数据集\n",
    "2. fetch_20newsgroups: 20个新闻组数据集\n",
    "3. fetch_lfw_people: 户外人脸识别数据集\n",
    "4. fetch_lfw_pairs: 户外人脸对数据集(同一个人两个图片)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "['DESCR', 'data', 'feature_names', 'filename', 'target']\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print(type(boston))\n",
    "print(dir(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 永远都是 x 在前面，先训练后测试\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K近邻算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "它的原理是求两点之间的距离，看谁的距离最近，以此来区分要预测的数据是属于那个分类\n",
    "使用sklearn实现K近邻算法:\n",
    "sklearn.neighbors.KNeighborsClassifier(n_neighbors = 5, algorithm = 'auto')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = np.array([ [0, 0],\n",
    "    [0.1, 0.2],\n",
    "    [1, 1],\n",
    "    [1.1, 0.9]] )\n",
    "labels = ['A', 'A', 'B', 'B']\n",
    "df = pd.DataFrame(values, labels)\n",
    "axis = sns.scatterplot(values[:, 0], values[:, 1])\n",
    "for value, label in zip(values, labels):\n",
    "    axis.text(value[0], value[1], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(values, labels)\n",
    "knn.predict([[0.3, 0.3]])  # 要给出二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B'], dtype='<U1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([[1.3, 0.6]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.neighbors import KNeighborsClassifier\\nimport pandas as pd\\nimport numpy as np\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndf = pd.read_csv('C:/Users/jiangyu/Desktop/datingTestSets', sep = '\\t', names = ['flight', 'icecream', 'game', 'tppe'])\\ndf.head()\\nfeatures = df.drop(columns = ['type'], axis = 0)  # 去掉type这一列数据，把其他列数据返回给features变量\\ntargets = df['type']\\nX_train, X_test, y_train, y_test = train_test_split(features, targets, test_szie = 0.25)\\nknn = KNeighborsClassifier()\\nknn.fit(X_train, y_train)\\nknn.score(X_test, y_test)  # 0.812\\nknn.predict([[40000, 10, 0.5]])  # array(['largeDoses'], dtype = object)\\n\\n# 标准化\\nscaler = StandarScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_test = scaler.fit_transform(X_test)\\nknn.fit(X_train, y_train)\\nknn.score(X_test, y_test)  # 0.96\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('C:/Users/jiangyu/Desktop/datingTestSets', sep = '\\t', names = ['flight', 'icecream', 'game', 'tppe'])\n",
    "df.head()\n",
    "features = df.drop(columns = ['type'], axis = 0)  # 去掉type这一列数据，把其他列数据返回给features变量\n",
    "targets = df['type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_szie = 0.25)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)  # 0.812\n",
    "knn.predict([[40000, 10, 0.5]])  # array(['largeDoses'], dtype = object)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandarScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)  # 0.96\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K近邻算法练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关库\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  # 训练集和测试集划分工具\n",
    "from sklearn.preprocessing import StandardScaler  # 标准化工具\n",
    "from sklearn.neighbors import KNeighborsClassifier  # K近邻算法库\n",
    "from sklearn.datasets import load_wine  # 导入红酒数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(wine.data)\n",
    "targets = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x训练数据集求得分\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.25)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 联合概率：指多个条件同时满足的概率  \n",
    "# 条件概率：指 A 事件满足情况下，B 事件发生的概率\n",
    "# 朴素贝叶斯公式：P(A|B) = [P(B|A) * P(A)] / P(B)\n",
    "# P(A|B) ：某个关键词属于某个分类的概率\n",
    "# P(B|A) ：某个分类下，某个关键词出现的概率\n",
    "# P(A) ：某个类别的概率\n",
    "# P(B) ：这个关键词在需要预测的文档中出现的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>科技类</th>\n",
       "      <th>娱乐类</th>\n",
       "      <th>汇总</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>明星</th>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>影院</th>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>云计算</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>支付宝</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>汇总</th>\n",
       "      <td>100</td>\n",
       "      <td>121</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     科技类  娱乐类   汇总\n",
       "明星     9   51   60\n",
       "影院     8   56   64\n",
       "云计算   63    0   63\n",
       "支付宝   20   15   35\n",
       "汇总   100  121  221"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat1 = {'科技类':{'明星': 9, '影院': 8, '云计算':63, '支付宝': 20, '汇总': 100},\n",
    "        '娱乐类':{'明星': 51, '影院': 56, '云计算':0, '支付宝': 15, '汇总': 121},\n",
    "        '汇总':{'明星': 60, '影院': 64, '云计算':63, '支付宝': 35, '汇总': 221}}\n",
    "a = pd.DataFrame(dat1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在有一篇文章包含 影院，支付宝，云计算 试分析该文章属于哪个类别的概率大一些\n",
    "# P(科技|影视，支付宝，云计算) = P(影视，支付宝，云计算|科技) * P(科技) = (8 / 100) * (20 / 100) * (63 / 100) * (100 / 121)\n",
    "# P(娱乐|影视，支付宝，云计算) = P(影视，支付宝，云计算|娱乐) * P(娱乐) = (56 / 121) * (35 / 121) * (63 / 121) * (121 / 221)\n",
    "# 拉普拉斯平滑系数 ：为避免出现概率为 0 的情况，其值默认为 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 项目实战：文章分类\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 文本提取库\n",
    "from sklearn.datasets import fetch_20newsgroups  # 远程数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'is', 'it', 'life', 'love', 'makes', 'me', 'python', 'short', 'use']\n",
      "[[0 1 0 1 0 0 0 1 1 1]\n",
      " [1 0 1 0 1 1 1 1 0 0]]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "world1 = 'Life is short, I use Python'\n",
    "world2 = 'I love Python, it makes me happy'\n",
    "vect = CountVectorizer()\n",
    "words = vect.fit_transform([world1, world2])\n",
    "names = vect.get_feature_names()\n",
    "print(names)\n",
    "print(words.toarray())\n",
    "print(type(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289148108872393"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups()\n",
    "# newsgroups.target_names\n",
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size = 0.25)\n",
    "news_vect = CountVectorizer()\n",
    "X_train = news_vect.fit_transform(X_train)  # 提取特征,然后再矩阵化\n",
    "X_test = news_vect.transform(X_test)  # 只矩阵化\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 朴素贝叶斯算法\n",
    "# 1. 多项式模型，应用于离散性数据，比如：文档分类，垃圾邮件识别等。使用的类是：sklearn.navie_bayes.MultinomialNB\n",
    "# 2. 高斯模型，应用于连续性数据采用。使用的类是：sklearn.navie_bayes.GaussianNB\n",
    "# 3. 伯努利模型，应用于特征值都是 0 和 1 的情况下。使用的类是：sklearn.navie_bayes.BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n信息熵 H(x) = -1 * np.sum(pi * np.ldg(pi)) (比特)\\n信息熵越大，数据越分散，有点类似方差\\n信息增益：表示特征 x 使得类 y 的不确定性减少的程度\\n决策树算法：ID3、C4.5、CART\\n预剪枝：决策树建立过程进行修剪可以降低过拟合\\n后剪枝：决策树建立之后再进行修剪\\n\\nSklearn实现决策树:可以通过sklearn.tree.DecisionTreeClassifier来实现决策树\\n1. criterion: gini(基尼系数) 或则 entroy(信息熵)\\n2. splitter: best 或则 random\\n3. max_depth: 树的最大深度\\n4. min_samples_split: 决策树中某个叶子节点的样本最小个数\\n5. min_weight_fraction_leaf: 叶子节点所有样本权重和的最小值\\n6. max_leaf_nodes: 最大的叶子节点个数\\n7. class_weight: 指定样本各特征的权重\\n8. min_impurity_decrease: 最小的不纯度\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "信息熵 H(x) = -1 * np.sum(pi * np.ldg(pi)) (比特)\n",
    "信息熵越大，数据越分散，有点类似方差\n",
    "信息增益：表示特征 x 使得类 y 的不确定性减少的程度\n",
    "决策树算法：ID3、C4.5、CART\n",
    "预剪枝：决策树建立过程进行修剪可以降低过拟合\n",
    "后剪枝：决策树建立之后再进行修剪\n",
    "\n",
    "Sklearn实现决策树:可以通过sklearn.tree.DecisionTreeClassifier来实现决策树\n",
    "1. criterion: gini(基尼系数) 或则 entroy(信息熵)\n",
    "2. splitter: best 或则 random\n",
    "3. max_depth: 树的最大深度\n",
    "4. min_samples_split: 决策树中某个叶子节点的样本最小个数\n",
    "5. min_weight_fraction_leaf: 叶子节点所有样本权重和的最小值\n",
    "6. max_leaf_nodes: 最大的叶子节点个数\n",
    "7. class_weight: 指定样本各特征的权重\n",
    "8. min_impurity_decrease: 最小的不纯度\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
